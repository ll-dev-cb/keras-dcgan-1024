{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "predict creates images from a saved generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from numpy import save\n",
    "import pandas as pd \n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "#import os\n",
    "#print(os.listdir(\"inputs\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import tensorflow as tf\n",
    "#import glob\n",
    "#from glob import glob\n",
    "import datetime\n",
    "import random\n",
    "from PIL import Image\n",
    "#import matplotlib\n",
    "#matplotlib.use('agg')\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "#import seaborn as sns\n",
    "#%matplotlib inline\n",
    "\n",
    "# to choose which GPU should be used\n",
    "#import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "#os.environ[\"HIP_VISIBLE_DEVICES\"]=\"1\"\n",
    "\n",
    "\n",
    "# this section will allow code to be run on a RTX GPU\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as keras\n",
    "#from keras.layers import Input, Dense, Reshape, Flatten, Dropout, GaussianNoise\n",
    "#from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "#from keras.layers.advanced_activations import LeakyReLU\n",
    "#from keras.layers.convolutional import UpSampling2D, Conv2D , Conv2DTranspose\n",
    "from tensorflow.compat.v1.models import Sequential, Model, load_model\n",
    "from tensorflow.compat.v1.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "IMAGE_SIZE = 1024\n",
    "NOISE_SIZE = 100\n",
    "\n",
    "#runtime \n",
    "MODEL_EPOCH = 1712 # current rect art \n",
    "MODEL_EPOCH = 306\n",
    "LOAD_WEIGHTS_EP = 19\n",
    "\n",
    "SAMPLES_TO_SHOW = 10\n",
    "EPOCHS_TO_RUN = 50\n",
    "\n",
    "MODEL_NAME = 'models/' + 'gan-' + str(IMAGE_SIZE) + '-' + str(NOISE_SIZE) + '-model.' + str(MODEL_EPOCH) + '.' + 'h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model = load_model(MODEL_NAME)\n",
    "#model.summary()\n",
    "model.load_weights(\"weights/gan-\" + str(IMAGE_SIZE) + \"-100-weights.\" + str(LOAD_WEIGHTS_EP) + \".h5\", by_name=True)\n",
    "generator = model.get_layer(name=\"model_2\")\n",
    "#generator = model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(input_z, epoch):\n",
    "    samples = generator.predict(input_z[:SAMPLES_TO_SHOW])\n",
    "    \n",
    "    # added for comparing the value\n",
    "    np.savetxt(noise_file_handle,input_z[:SAMPLES_TO_SHOW], delimiter=',')\n",
    "    \n",
    "    sample_images = [((sample + 1.0) * 127.5).astype(np.uint8) for sample in samples]\n",
    "    name = OUTPUT_DIR + \"samples\"\n",
    "    print(\"save images\")\n",
    "    for index in range(SAMPLES_TO_SHOW):\n",
    "        image_array = sample_images[index]\n",
    "        image = Image.fromarray(image_array)\n",
    "        image.save(name+\"_\"+str(epoch).zfill(3) + \"_\" + str(index).zfill(3) +\".png\") \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Paths\n",
    "\n",
    "OUTPUT_DIR = './gen-' + '{date:%Y-%m-%d_%H_%M_%S}/'.format(date=datetime.datetime.now())\n",
    "if not os.path.exists(OUTPUT_DIR):\n",
    "    os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "SAMPLE_NOISE_FILE = OUTPUT_DIR + \"sample_noise.csv\"\n",
    "noise_file_handle = open(SAMPLE_NOISE_FILE,'a')\n",
    "    \n",
    "for index in range(EPOCHS_TO_RUN):\n",
    "    print('generating images, set ' + str(index))\n",
    "    noise_data = np.random.normal(0, 1, size=(SAMPLES_TO_SHOW, NOISE_SIZE))\n",
    "    predict(noise_data,index)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
